# Session-3

In this Assigment, the task is to acheive validation accuracy more than 99.4% on mnist data set by training a DNN with less than 20000 parameters.

I tried several architecture. Could acheive 99.08% at max ( without using any dropout / batch normalization etc. ).
Given below are the best model and second best model ((i could acheive)).


## Model1 :- validation Accuracy =99.08% with 15,650 parameters
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_109 (Conv2D)          (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_110 (Conv2D)          (None, 24, 24, 32)        9248      
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 24, 24, 10)        330       
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 12, 12, 10)        0         
_________________________________________________________________
conv2d_112 (Conv2D)          (None, 10, 10, 32)        2912      
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 10, 10, 10)        330       
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 5, 5, 10)          0         
_________________________________________________________________
conv2d_114 (Conv2D)          (None, 1, 1, 10)          2510      
_________________________________________________________________
flatten_12 (Flatten)         (None, 10)                0         
_________________________________________________________________
activation_12 (Activation)   (None, 10)                0         
=================================================================
Total params: 15,650
Trainable params: 15,650
Non-trainable params: 0
___________________________________________________________


## Model2 :- validation Accuracy =98.95% with 14,960 parameters

Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_167 (Conv2D)          (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_168 (Conv2D)          (None, 24, 24, 32)        9248      
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 24, 24, 10)        330       
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 12, 12, 10)        0         
_________________________________________________________________
conv2d_170 (Conv2D)          (None, 10, 10, 32)        2912      
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 10, 10, 10)        330       
_________________________________________________________________
max_pooling2d_42 (MaxPooling (None, 5, 5, 10)          0         
_________________________________________________________________
conv2d_172 (Conv2D)          (None, 3, 3, 10)          910       
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 1, 1, 10)          910       
_________________________________________________________________
flatten_16 (Flatten)         (None, 10)                0         
_________________________________________________________________
activation_16 (Activation)   (None, 10)                0         
=================================================================
Total params: 14,960
Trainable params: 14,960
Non-trainable params: 0
_________________________________________________________________





